@page "/Chat"
@using System.Data.SqlTypes
@using System.Numerics
@using System.Text
@using AngleSharp.Css
@using m1Chat.Client.Components
@using m1Chat.Client.Services
@inject IScrollManager ScrollManager
@inject ChatCompletionService CompletionService
@inject ChatService ChatService
@inject FileUploadService FileUploadService
@inject IJSRuntime Js
@using ServiceChatMessage = m1Chat.Client.Services.ChatMessage
@inject UserService UserService
@inject ISnackbar Snackbar
@inject NavigationManager NavigationManager
@inject ChatCacheService ChatCacheService
@inject SvgIcons SvgIcons
@inject ModelPreferencesService ModelPreferences

<MudLayout>
  <ChatDrawer @bind-DrawerOpen="_drawerOpen"
              @ref="_chatDrawerRef"
              SidebarChats="SidebarChats"
              UserEmail="@UserEmail"
              ActiveChatId="@_chatId"
              OnChatSelected="LoadChat"
              OnCreateNewChat="CreateNewChat"
              OnChatPinned="PinChat"
              OnChatDeleted="DeleteChat"
              OnChatRenamed="HandleChatRenamed"/>

  <MudMainContent
    Class="d-flex flex-column p-0 chat-main-content-bg"
    Style="height:100vh;overflow:hidden;"
  >
    @if (!_drawerOpen)
    {
      <MudIconGroup
        class="ma-2 pa-2 translucent-paper rounded-xl"
        Style="position: fixed; left: 0; top: 0; z-index: 100;"
      >
        <MudIconButton
          Icon="@SvgIcons.SideBar"
          Size="Size.Small"
          OnClick="() => _drawerOpen = true"
          class="mr-2"
        >
        </MudIconButton>
        <MudIconButton
          Icon="@SvgIcons.Search"
          Size="Size.Small"
          OnClick="FocusSearchFieldInDrawer"
          class="mr-2"
        >
        </MudIconButton>
        <MudIconButton Icon="@SvgIcons.New" Size="Size.Small" OnClick="CreateNewChat">
        </MudIconButton>
      </MudIconGroup>
    }

    <div
      class="chat-container px-2 pb-2 no-scrollbar"
      @ref="_chatContainerRef"
      style="overflow-y:auto; flex:1 1 auto; padding-bottom: 130px;"
      id="chat-view"
    >
      <MudPaper Elevation="0">
        <MudStack Spacing="4">
          @foreach (var m in _chatHistory)
          {
            if (m.IsUser)
            {
              <MudStack @key="m.Id">
                <div class="user-message-container">
                  @if (m.FileIds != null && m.FileIds.Any())
                  {
                    <div class="attached-files-display mb-2">
                      <MudText Typo="Typo.caption" Color="Color.Secondary">Attached Files:</MudText>
                      @foreach (var fileId in m.FileIds)
                      {
                        <MudChip T="string" Size="Size.Small" Variant="Variant.Outlined"
                                 Icon="@Icons.Material.Filled.AttachFile">
                          File: @(fileId.ToString().Length > 8 ? fileId.ToString()[..8] + "..." : fileId.ToString())
                        </MudChip>
                      }
                    </div>
                  }
                  <MudChat ChatPosition="ChatBubblePosition.Start" ArrowPosition="ChatArrowPosition.None">
                    <MudChatBubble
                      Variant="Variant.Text"
                      Class="user-message rounded-xl text-align-left"
                    >
                      <UserMarkdown Markdown="@m.Text"/>
                    </MudChatBubble>
                  </MudChat>
                  <div class="message-actions">
                    <span @onclick:stopPropagation="true">
                      <MudTooltip Text="Retry message">
                        <MudIconButton
                          Icon="@Icons.Material.Filled.Refresh"
                          Size="Size.Small"
                          OnClick="@(() => HandleRegenerateMessage(m))"
                          aria-label="Regenerate"/>
                      </MudTooltip>
                    </span>
                    <span @onclick:stopPropagation="true">
                      <MudTooltip Text="Edit message">
                        <MudIconButton
                          Icon="@Icons.Material.Filled.Edit"
                          Size="Size.Small"
                          OnClick="@(() => HandleEditMessage(m))"
                          aria-label="Edit"/>
                      </MudTooltip>
                    </span>
                    <span @onclick:stopPropagation="true">
                      <MudTooltip Text="Copy message">
                        <MudIconButton
                          Icon="@Icons.Material.Filled.ContentCopy"
                          Size="Size.Small"
                          OnClick="@(async () => await HandleCopyMessage(m))"
                          aria-label="Copy"/>
                      </MudTooltip>
                    </span>
                  </div>
                  <div class="user-message-hoverzone"></div>
                </div>
              </MudStack>
            }
            else
            {
              <MudStack @key="m.Id">
                <div class="ai-message-container">
                  <AiMarkdown Markdown="@m.Text" IsStreaming="@m.IsStreaming"/>
                  <div class="message-actions">
                    <span @onclick:stopPropagation="true">
                      <MudTooltip Text="Copy message">
                        <MudIconButton
                          Icon="@Icons.Material.Filled.ContentCopy"
                          Size="Size.Small"
                          OnClick="@(async () => await HandleCopyMessage(m))"
                          aria-label="Copy"/>
                      </MudTooltip>
                    </span>
                    <span @onclick:stopPropagation="true">
                      <MudTooltip Text="Branch off">
                        <MudIconButton
                          Icon="@Icons.Material.Filled.MergeType"
                          Size="Size.Small"
                          OnClick="@(() => HandleBranchMessage(m))"
                          aria-label="Branch"/>
                      </MudTooltip>
                    </span>
                    <span @onclick:stopPropagation="true">
                      <MudTooltip Text="Retry message">
                        <MudIconButton
                          Icon="@Icons.Material.Filled.Refresh"
                          Size="Size.Small"
                          OnClick="@(() => HandleRegenerateMessage(m))"
                          aria-label="Regenerate"/>
                      </MudTooltip>
                    </span>
                  </div>
                  <div class="ai-message-hoverzone"></div>
                </div>
              </MudStack>
            }
          }
        </MudStack>
      </MudPaper>
    </div>

    <div class="input-area-container">
      <ScrollToBottomChip></ScrollToBottomChip>
      <MudPaper Elevation="3" Outlined="true"
                Class="border-solid border-1 border-b-0 mud-border-primary rounded-t-xl px-4 pt-4 translucent-paper background-hack">
        <MudContainer Class="pa-0">
          <div style="display:flex;flex-direction:column;">
            <!-- File Upload Component - Animate its appearance -->
            <div class="file-upload-container @(_showFileUpload ? "file-upload-visible" : "file-upload-hidden")">
              <div class="mb-2">
                <MudStack Row Class="mb-2 justify-space-between align-center">
                  <MudText Typo="Typo.subtitle2" Color="Color.Primary">
                    Attach Files
                  </MudText>
                  <MudIconButton
                    Icon="@Icons.Material.Filled.Close"
                    Size="Size.Small"
                    OnClick="() => _showFileUpload = false"
                    Color="Color.Secondary"
                    aria-label="Close file upload"
                  />
                </MudStack>
                <FileUploadComponent @ref="_fileUploadComponentRef" @bind-UploadedFiles="CurrentMessageFiles"/>
              </div>
            </div>

            <div style="display:flex;align-items:center;">
              <MudTextField
                @ref="_messageTextField"
                @bind-Value="MessageText"
                Label="Enter your message"
                Margin="Margin.None"
                Variant="Variant.Text"
                AutoGrow="true"
                AutoFocus="true"
                Underline="false"
                Lines="2"
                MaxLines="10"
                Class="flex-grow-1"
                Immediate="false"
                OnKeyUp="HandleKeyUp"
              />
            </div>
            <div
              style="display:flex;align-items:center;margin-top:8px;">
              
              <MudSelect @ref="_modelSelect"
                         @bind-Value="ChatSelectedModel"
                         Variant="Variant.Text"
                         Margin="Margin.None"
                         Underline="false"
                         FitContent="true"
                         Typo="Typo.body1"
                         MaxHeight="int.MaxValue"
                         Class="mr-2"
                         AnchorOrigin="Origin.BottomCenter">
                @foreach (var providerGroup in _enabledModelsByProvider.OrderBy(kvp => kvp.Key)) 
                {
                    @foreach (var model in providerGroup.Value) 
                    {
                        <MudSelectItem Value="@model">@model</MudSelectItem>
                    }
                }
              </MudSelect>
              

              <div style="display:flex; align-items:center;"
                   class="@(_isThinkingSelectorDisabled ? "mud-text-secondary" : "mud-text-primary")">
                <div class="think-icon-text">
                  <MudButton Variant="Variant.Text"
                             OnClick="ToggleMenuAsync"
                             Disabled="@_isThinkingSelectorDisabled">
                    <MudText Typo="Typo.body1">
                      @ThinkingSelectedOption
                    </MudText>
                  </MudButton>
                </div>
                <MudMenu @ref="_mudMenu"
                         Icon="@CurrentThinkingIcon"
                         Color="Color.Primary"
                         AriaLabel="Thinking options"
                         Disabled="@_isThinkingSelectorDisabled"
                         AnchorOrigin="Origin.TopRight"
                         Class="rounded-xl"
                         TransformOrigin="Origin.BottomRight">
                  @foreach (var opt in _currentThinkingOptions)
                  {
                    <MudMenuItem OnClick="() => SetThinkingOption(opt)" Class="px-3 py-1" Style="min-width: 120px;">
                      <div class="d-flex align-center">
                        <MudIcon Icon="@GetThinkingOptionIcon(opt)" Size="Size.Small" Class="mr-2"
                                 Style="margin-top: -2px;"/>
                        <MudText Typo="Typo.body1">@opt</MudText>
                      </div>
                    </MudMenuItem>
                  }
                </MudMenu>
              </div>


              <div
                style="margin-left:auto;display:flex;align-items:center;">
                <MudIconButton
                  Icon="@(_showFileUpload ? Icons.Material.Filled.AttachFile : Icons.Material.Filled.AttachFile)"
                  Color="@(_showFileUpload ? Color.Success : Color.Primary)"
                  OnClick="ToggleFileUpload"
                  aria-label="@(_showFileUpload ? "Hide file upload" : "Show file upload")"
                  Class="mr-2"/>
                @if (CurrentMessageFiles.Any())
                {
                  <MudChip T="string"
                           Size="Size.Small"
                           Color="Color.Primary"
                           Icon="@Icons.Material.Filled.AttachFile"
                           Class="mr-2">
                    @CurrentMessageFiles.Count file@(CurrentMessageFiles.Count == 1 ? "" : "s")
                  </MudChip>
                }
                <MudIconButton
                  Variant="Variant.Filled"
                  Color="Color.Primary"
                  Icon="@Icons.Material.Filled.Send"
                  OnClick="SendMessage"
                  aria-label="Send message"
                  Disabled="@_isSendingMessage">
                </MudIconButton>
              </div>
            </div>
          </div>
        </MudContainer>
      </MudPaper>
    </div>
  </MudMainContent>
</MudLayout>

@code {
  private bool _drawerOpen = true;
  private bool _needsScroll;
  private bool _isAtBottom = true;
  private bool _isSendingMessage = false;
  private bool _showFileUpload = false; // New state for showing/hiding file upload

  private ElementReference _chatContainerRef;

  private string UserEmail { get; set; } = "";
  private string MessageText { get; set; } = "";

  private ChatDrawer _chatDrawerRef;
  private MudSelect<string> _modelSelect; // Correct: Declare the MudSelect reference here!


  private ChatMessage? _messageBeingEdited; // New state variable to track the message being edited

  // File upload properties
  private List<FileUploadService.UploadedFileInfo> CurrentMessageFiles = new();
  private FileUploadComponent _fileUploadComponentRef;

  private string _chatSelectedModel = ""; // Initialize with an empty string or default

  private async Task Should_sidebar_be_open()
  {
    var width = await Js.InvokeAsync<int>("eval", "window.innerWidth");
    _drawerOpen = width > 768;
  }

  private string ChatSelectedModel
  {
    get => _chatSelectedModel;
    set
    {
      if (_chatSelectedModel != value)
      {
        _chatSelectedModel = value;
        ApplyThinkingOptionsForModel(value);
        StateHasChanged();
      }
    }
  }

  private string ThinkingSelectedOption { get; set; } = "None";

  private string CurrentThinkingIcon
  {
    get
    {
      return ThinkingSelectedOption switch
      {
        "None" => SvgIcons.BrainIcons[0],
        "Low" => SvgIcons.BrainIcons[1],
        "Medium" => SvgIcons.BrainIcons[2],
        "High" => SvgIcons.BrainIcons[3],
        _ => SvgIcons.BrainIcons[0] // Default case, e.g., if option is not recognized
      };
    }
  }

  private string GetThinkingOptionIcon(string option)
  {
    return option switch
    {
      "None" => SvgIcons.BrainIcons[0],
      "Low" => SvgIcons.BrainIcons[1],
      "Medium" => SvgIcons.BrainIcons[2],
      "High" => SvgIcons.BrainIcons[3],
      _ => SvgIcons.BrainIcons[0] // Default case, e.g., if option is not recognized
    };
  }

  private bool _isThinkingSelectorDisabled = false;
  private List<string> _currentThinkingOptions = new();

  private static readonly List<string> ThinkingOptionsLowMediumHigh = new() { "Low", "Medium", "High" };
  private static readonly List<string> ThinkingOptionsNoneLowMediumHigh = new() { "None", "Low", "Medium", "High" };
  private static readonly List<string> ThinkingOptionsNoneOnly = new() { "None" };

  private Dictionary<string, List<string>> _modelThinkingOptionsMap;

  // This will hold the models grouped by provider for the MudSelect
  private Dictionary<string, List<string>> _enabledModelsByProvider = new();

  // The full list of models, used for internal mapping and initial population
  // Correct: Access GetAllAvailableModels() via the injected instance
  private List<string> _allAiModelOptions;


  private string? _chatId;
  private string _chatName = "New Chat";
  private List<ChatMessage?> _chatHistory = new();
  private bool _chatIsPinned;
  private MudTextField<string> _messageTextField;
  private List<ChatDrawer.SidebarChat> SidebarChats = new();

  [Inject] private SignalRService SignalRService { get; set; } = null!;
  [Inject] private ChatCompletionService ChatCompletionService { get; set; } = null!;

  protected override async Task OnInitializedAsync()
  {
    UserEmail = await UserService.GetUserEmailAsync() ?? "Unknown";
    await LoadSidebarChatsAsync();
    _ = Should_sidebar_be_open();

    // Initialize ModelPreferences service and load enabled models
    await ModelPreferences.InitializeAsync();
    // Correct: Populate _allAiModelOptions from the service instance
    _allAiModelOptions = ModelPreferences.GetAllAvailableModels(); 
    GroupEnabledModelsByProvider();

    // Set initial selected model to the first available if current is not enabled
    if (!_enabledModelsByProvider.Any())
    {
        // If no models are enabled in preferences, default to all models and select the first one
        _enabledModelsByProvider = ModelPreferences.GetAllAvailableModels()
            .GroupBy(m => ModelPreferences.GetModelProviders().GetValueOrDefault(m, "Unknown"))
            .ToDictionary(g => g.Key, g => g.ToList());
        _chatSelectedModel = _enabledModelsByProvider.Values.SelectMany(x => x).FirstOrDefault() ?? "";
    }
    else if (!ModelPreferences.EnabledModels.Contains(_chatSelectedModel))
    {
         _chatSelectedModel = ModelPreferences.EnabledModels.FirstOrDefault() ?? "";
    }
    
    // Ensure ChatSelectedModel is not null or empty if there are available models
    if (string.IsNullOrEmpty(_chatSelectedModel) && _enabledModelsByProvider.Any())
    {
        _chatSelectedModel = _enabledModelsByProvider.Values.SelectMany(x => x).FirstOrDefault() ?? "";
    }


    _modelThinkingOptionsMap = new Dictionary<string, List<string>>()
    {
      { "Deepseek v3", ThinkingOptionsNoneOnly },
      { "DeepSeek Prover v2", ThinkingOptionsLowMediumHigh }, // Keeping this here for future use or full context
      { "Deepseek r1", ThinkingOptionsLowMediumHigh }, // Keeping this here for future use or full context
      { "Deepseek R1 0528", ThinkingOptionsNoneOnly },
      { "DeepSeek r1 v3 Chimera", ThinkingOptionsLowMediumHigh }, // Keeping this here for future use or full context
      { "Gemini 2.5 Pro", ThinkingOptionsNoneOnly }, // Keeping this here for future use or full context
      { "Gemini 2.5 Flash", ThinkingOptionsNoneLowMediumHigh },
      { "Gemini 2.0 Flash", ThinkingOptionsNoneOnly },
      { "Qwen3 235B", ThinkingOptionsLowMediumHigh }, // Keeping this here for future use or full context
      { "Qwen3 30B", ThinkingOptionsLowMediumHigh }, // Keeping this here for future use or full context
      { "Gemma 3 27B", ThinkingOptionsNoneOnly },
      { "Devstral Small", ThinkingOptionsNoneOnly },
      { "Magistral Small", ThinkingOptionsNoneOnly }, // Keeping this here for future use or full context
      { "Mistral Medium", ThinkingOptionsNoneOnly },
      { "Magistral Medium", ThinkingOptionsNoneOnly }, // Keeping this here for future use or full context
      { "Llama 3.1 8B", ThinkingOptionsNoneOnly },
      { "Llama 4 Scout", ThinkingOptionsNoneOnly },
      { "Llama 4 Maverick", ThinkingOptionsNoneOnly }
    };

    ApplyThinkingOptionsForModel(ChatSelectedModel);
    if (OperatingSystem.IsBrowser())
    {
      await Js.InvokeVoidAsync("window.hideBlazorLoadingScreen");
      await SignalRService.EnsureConnectionAsync();
    }
  }

  private void GroupEnabledModelsByProvider()
  {
      // Correct: Access GetModelProviders() via the injected instance
      var providerMap = ModelPreferences.GetModelProviders(); 
      _enabledModelsByProvider = ModelPreferences.EnabledModels
          .Where(modelName => providerMap.ContainsKey(modelName)) // Ensure model exists in provider map
          .GroupBy(modelName => providerMap[modelName])
          .ToDictionary(group => group.Key, group => group.ToList());
  }

  private async Task FocusSearchFieldInDrawer()
  {
    // Open drawer if closed
    if (!_drawerOpen)
    {
      _drawerOpen = true;
      await InvokeAsync(StateHasChanged);

      // Small delay to ensure drawer is rendered
      //await Task.Delay(50);
    }

    if (_chatDrawerRef != null)
    {
      await _chatDrawerRef.FocusSearchFieldAsync();
    }
  }


  // Changed this method to async Task as it will be called by SignalRService.OnStreamCompleted (which is now Func<Task>)
  private async Task HandleStreamCompleted()
  {
    var aiMessage = _chatHistory.LastOrDefault(m => !m.IsUser && m.IsStreaming);
    if (aiMessage != null)
    {
      aiMessage.IsStreaming = false;
      _isSendingMessage = false;
      StateHasChanged();
      await SaveChatAfterStreaming(); // Await this now
    }
  }

  // HandleChunkReceived and HandleStreamError remain the same, as they are passed as Actions.
  private void HandleChunkReceived(string chunk)
  {
    var aiMessage = _chatHistory.LastOrDefault(m => !m.IsUser && m.IsStreaming);
    if (aiMessage != null)
    {
      aiMessage.Text += chunk;
      _needsScroll = true;
      StateHasChanged();
    }
  }

  private async Task ScrollToBottom()
  {
    await ScrollManager.ScrollToBottomAsync(".chat-container", ScrollBehavior.Smooth);
  }

  private void HandleStreamError(string error)
  {
    var aiMessage = _chatHistory.LastOrDefault(m => !m.IsUser && m.IsStreaming);
    if (aiMessage != null)
    {
      aiMessage.Text = $"[Error: {error}]";
      aiMessage.IsStreaming = false;
      _isSendingMessage = false;
      StateHasChanged();
    }
  }

  private async Task SaveChatAfterStreaming()
  {
    if (Guid.TryParse(_chatId, out var cId))
    {
      var updateReq = new ChatService.UpdateChatRequest(
        _chatName,
        ChatSelectedModel,
        ToSharedMessagesWithFilesForDb().ToArray(),
        _chatIsPinned
      );
      await ChatService.UpdateChatAsync(cId, updateReq);
      ChatCacheService.InvalidateCache(cId);
      await LoadSidebarChatsAsync(); // Await this to ensure sidebar is updated
    }
  }

  private void SetThinkingOption(string option)
  {
    if (ThinkingSelectedOption != option)
    {
      ThinkingSelectedOption = option;
      StateHasChanged(); // Essential to re-render the component and update the displayed text
    }
  }


  private int EstimateTokens()
  {
    var characters = MessageText.Length;
    var tokens = characters / 4.2;
    return (int)Math.Round(tokens);
  }


  private void HandleChatModelChanged(string newModel)
  {
    ChatSelectedModel = newModel;
    ApplyThinkingOptionsForModel(newModel);
    StateHasChanged();
  }

  private void ApplyThinkingOptionsForModel(string modelName)
  {
    if (_modelThinkingOptionsMap.TryGetValue(modelName, out var options))
    {
      _currentThinkingOptions = options;
      // Special case for 'llama-3.1-8b-instant' - ensure it's not removed if present in the map
      if (modelName == "llama-3.1-8b-instant")
      {
        _isThinkingSelectorDisabled = true;
        ThinkingSelectedOption = "None";
      }
      else
      {
        _isThinkingSelectorDisabled = false;
        if (!_currentThinkingOptions.Contains(ThinkingSelectedOption))
        {
          ThinkingSelectedOption = _currentThinkingOptions.FirstOrDefault() ?? "None";
        }
      }
    }
    else
    {
      // Fallback for models not explicitly mapped or if modelName is empty/invalid
      _currentThinkingOptions = ThinkingOptionsNoneLowMediumHigh;
      _isThinkingSelectorDisabled = false;
      if (!_currentThinkingOptions.Contains(ThinkingSelectedOption))
        {
            ThinkingSelectedOption = "None";
        }
    }
  }

  private async Task LoadSidebarChatsAsync()
  {
    var list = await ChatService.GetChatsAsync();
    SidebarChats = list
      .OrderByDescending(c => c.IsPinned)
      .ThenByDescending(c => c.LastUpdatedAt)
      .Select(c => new ChatDrawer.SidebarChat(c.Id.ToString(), c.Name, c.Model, c.IsPinned, c.LastUpdatedAt))
      .ToList();
    // No StateHasChanged here, as it's typically called by the caller after this
  }

  private async Task CreateNewChat()
  {
    _chatId = null;
    _chatName = "New Chat";
    _chatHistory.Clear();
    _chatIsPinned = false;
    CurrentMessageFiles.Clear();
    _showFileUpload = false; // Hide file upload when creating new chat
    _messageBeingEdited = null; // Clear editing state
    StateHasChanged();
  }

  private async Task LoadChat(ChatDrawer.SidebarChat chat)
  {
    if (_chatId == chat.Id && _chatHistory.Any()) return;
    // Check cache first
    if (Guid.TryParse(chat.Id, out var chatGuid))
    {
      var cached = ChatCacheService.GetChatIfCached(chatGuid);
      if (cached != null)
      {
        ApplyCachedChat(cached);
        return;
      }
    }

    _chatHistory.Clear();
    var fullChat = await ChatService.GetChatAsync(Guid.Parse(chat.Id));
    _chatId = fullChat.Id.ToString();
    _chatName = fullChat.Name;
    ChatSelectedModel = fullChat.Model;
    ApplyThinkingOptionsForModel(fullChat.Model);
    _chatIsPinned = fullChat.IsPinned;
    _chatHistory = fullChat.Messages
      .Select(m => new ChatMessage // m here is ChatService.ChatMessageDto
      {
        IsUser = m.Role == "user",
        Text = m.Content, // Correct: DTO has Content, local record has Text
        FileIds = m.FileIds?.ToList() ?? new List<Guid>()
      })
      .ToList();
    CurrentMessageFiles.Clear();
    _showFileUpload = false; // Hide file upload when loading chat
    _messageBeingEdited = null; // Clear editing state
    _needsScroll = true;
    StateHasChanged();
  }

  private void ApplyCachedChat(ChatService.ChatHistory cached)
  {
    _chatId = cached.Id.ToString();
    _chatName = cached.Name;
    ChatSelectedModel = cached.Model;
    ApplyThinkingOptionsForModel(cached.Model);
    _chatIsPinned = cached.IsPinned;
    _chatHistory = cached.Messages
      .Select(m => new ChatMessage
      {
        IsUser = m.Role == "user",
        Text = m.Content,
        FileIds = m.FileIds?.ToList() ?? new List<Guid>()
      })
      .ToList();

    CurrentMessageFiles.Clear();
    _showFileUpload = false;
    _messageBeingEdited = null;
    _needsScroll = true;
    StateHasChanged();
  }


  private List<ServiceChatMessage> ToServiceChatMessages() => // Renamed for clarity
    _chatHistory.Select(m => new ServiceChatMessage // This is m1Chat.Client.Services.ChatMessage
    {
      Role = m.IsUser ? "user" : "assistant",
      Content = m.Text, // m is local ChatMessage record, which has Text
      // FileIds are handled by ToSharedMessagesWithFilesForDb when saving
    }).ToList();

  [JSInvokable]
  public void SetAtBottom(bool atBottom) => _isAtBottom = atBottom;

  protected override async Task OnAfterRenderAsync(bool firstRender)
  {
    if (firstRender)
    {
      await Js.InvokeVoidAsync(
        "chatScroll.onScroll",
        _chatContainerRef,
        DotNetObjectReference.Create(this)
      );
    }

    if (_needsScroll && _isAtBottom)
    {
      await ScrollManager.ScrollToBottomAsync(
        ".chat-container",
        ScrollBehavior.Auto
      );
      _needsScroll = false;
    }
  }

  private async Task HandleKeyUp(KeyboardEventArgs args)
  {
    //return;
    if (args.Key == "Enter" && !args.ShiftKey)
    {
      await _messageTextField.BlurAsync();
      await _messageTextField.FocusAsync();
      if (!string.IsNullOrWhiteSpace(MessageText) || CurrentMessageFiles.Any())
      {
        await SendMessage();
      }
    }
  }

  private async Task SendMessage()
  {
    if (_isSendingMessage) return;
    await SignalRService.EnsureConnectionAsync();

    var textToSend = MessageText.Trim();
    if (string.IsNullOrWhiteSpace(textToSend) && !CurrentMessageFiles.Any())
    {
      return;
    }

    _isSendingMessage = true;
    StateHasChanged();

    var fileIds = CurrentMessageFiles.Select(f => f.Id).ToList();
    var userMessageTextForName = textToSend;

    if (_messageBeingEdited != null)
    {
      var originalMessageIndex = _chatHistory.IndexOf(_messageBeingEdited);
      if (originalMessageIndex != -1)
      {
        _chatHistory[originalMessageIndex] = _messageBeingEdited with
        {
          Text = textToSend,
          FileIds = fileIds
        };
        if (_messageBeingEdited.IsUser)
        {
          _chatHistory.RemoveAll(m => _chatHistory.IndexOf(m) > originalMessageIndex && !m.IsUser);
        }
      }

      _messageBeingEdited = null;
    }
    else
    {
      _chatHistory.Add(new ChatMessage
      {
        IsUser = true,
        Text = textToSend,
        FileIds = fileIds
      });
    }

    MessageText = "";
    CurrentMessageFiles.Clear();
    _showFileUpload = false;
    _isAtBottom = true;
    _needsScroll = true;
    StateHasChanged();

    bool isNewChat = _chatId == null;
    Guid newChatGuid = Guid.Empty;

    if (isNewChat)
    {
      _chatName = "New Chat";
      var initialMessagesForName = new List<ServiceChatMessage>
      {
        new() { Role = "user", Content = $"Generate a brief, relevant chat name (under 5 words, no quotes) for this conversation that starts with: \"{userMessageTextForName[..Math.Min(100, userMessageTextForName.Length)]}\"" }
      };

      string tempName = string.IsNullOrWhiteSpace(userMessageTextForName) ? "Chat with Files" : (userMessageTextForName.Length <= 20 ? userMessageTextForName : userMessageTextForName.Substring(0, 20) + "...");

      var createReq = new ChatService.CreateChatRequest(
        tempName,
        ChatSelectedModel,
        new ChatService.ChatMessageDto[] { new ChatService.ChatMessageDto("user", userMessageTextForName, fileIds) },
        _chatIsPinned
      );
      newChatGuid = await ChatService.CreateChatAsync(createReq);
      _chatId = newChatGuid.ToString();
      NavigationManager.NavigateTo($"/Chat?chatId={_chatId}", forceLoad: false);

      string generatedName = "";
      try
      {
        // Use an async Func<Task> for the completion callback
        var nameGenerationCompleteFunc = new Func<Task>(async () => // Changed to Func<Task>
        {
          _chatName = !string.IsNullOrWhiteSpace(generatedName)
            ? generatedName.Trim().Trim('"', '\'').Replace("\n", " ").Truncate(50)
            : tempName;

          var updateNameReq = new ChatService.UpdateChatRequest(
            _chatName,
            ChatSelectedModel,
            new ChatService.ChatMessageDto[] { new ChatService.ChatMessageDto("user", userMessageTextForName, fileIds) },
            _chatIsPinned
          );
          await ChatService.UpdateChatAsync(newChatGuid, updateNameReq); // Await this update
          ChatCacheService.InvalidateCache(newChatGuid); // Invalidate cache so next sidebar load is fresh
          await LoadSidebarChatsAsync(); // Await loading sidebar chats
          StateHasChanged(); // Re-render Chat component (and thus ChatDrawer)
        });

        // Start name generation streaming
        await ChatCompletionService.StreamCompletion(
          initialMessagesForName,
          "llama-3.1-8b-instant",
          "Low", // Or "None" if 'reasoningEffort' is not applicable to name generation model
          chunk => generatedName += chunk,
          nameGenerationCompleteFunc, // Pass the Func<Task>
          null
        );
      }
      catch (Exception ex)
      {
        Console.WriteLine($"Name generation failed: {ex.Message}");
        _chatName = tempName;
        // Ensure sidebar is loaded even if name generation failed
        await LoadSidebarChatsAsync();
        StateHasChanged();
      }
    }

    // Create new AI message with streaming enabled
    var aiMessage = new ChatMessage
    {
      IsUser = false,
      Text = "",
      IsStreaming = true
    };
    _chatHistory.Add(aiMessage);
    _needsScroll = true;
    StateHasChanged();

    try
    {
      // Prepare messages for AI
      var messagesForAiStartIdx = _messageBeingEdited != null ? _chatHistory.IndexOf(_messageBeingEdited) : 0;
      var messagesForAi = _chatHistory
        .Take(_chatHistory.Count - 1)
        .Select(m => new ServiceChatMessage
        {
          Role = m.IsUser ? "user" : "assistant",
          Content = m.Text,
          FileIds = m.FileIds
        }).Skip(messagesForAiStartIdx).ToList();

      // Buffering implementation
      var buffer = new System.Text.StringBuilder();
      var lastUpdateTime = DateTime.MinValue;
      var updateInterval = TimeSpan.FromMilliseconds(200);

      // Start streaming via SignalR
      await ChatCompletionService.StreamCompletion(
        messagesForAi,
        ChatSelectedModel,
        ThinkingSelectedOption,
        chunk =>
        {
          buffer.Append(chunk);

          var now = DateTime.UtcNow;
          if (now - lastUpdateTime >= updateInterval)
          {
            aiMessage.Text += buffer.ToString();
            buffer.Clear();
            lastUpdateTime = now;
            _needsScroll = true;
            StateHasChanged();
          }
        },
        async () => // This also needs to be async Func<Task> now
        {
          // Flush any remaining buffered content
          if (buffer.Length > 0)
          {
            aiMessage.Text += buffer.ToString();
            buffer.Clear();
          }

          aiMessage.IsStreaming = false;
          _isSendingMessage = false;
          StateHasChanged();
          await SaveChatAfterStreaming(); // Await this as well
        },
        error =>
        {
          if (buffer.Length > 0)
          {
            aiMessage.Text += buffer.ToString();
            buffer.Clear();
          }

          aiMessage.Text = $"[Error: {error}]";
          aiMessage.IsStreaming = false; // Should be false on error
          _isSendingMessage = false;
          StateHasChanged();
        }
      );
    }
    catch (Exception ex)
    {
      aiMessage.Text = $"[Error: {ex.Message}]";
      aiMessage.IsStreaming = true; // Should be false on error
      _isSendingMessage = false;
      Console.WriteLine($"Error streaming completion: {ex}");
      StateHasChanged();
    }
  }


  // Used for saving to DB via ChatService (expects DTOs with FileIds)
  private List<ChatService.ChatMessageDto> ToSharedMessagesWithFilesForDb() =>
    _chatHistory.Select(m => new ChatService.ChatMessageDto(
      m.IsUser ? "user" : "assistant",
      m.Text, // Corrected: m is local ChatMessage, which has .Text
      m.FileIds
    )).ToList();

  private void ToggleFileUpload()
  {
    _showFileUpload = !_showFileUpload;
    StateHasChanged();
  }

  private MudMenu _mudMenu;

  private async Task ToggleMenuAsync(MouseEventArgs args)
  {
    if (_mudMenu != null)
    {
      await _mudMenu.ToggleMenuAsync(args);
    }
  }


  private async Task TriggerFileUpload()
  {
    if (_fileUploadComponentRef != null)
    {
      await _fileUploadComponentRef.TriggerUploadAsync();
    }
    else
    {
      Snackbar.Add("File upload component not ready. Please try again.", Severity.Warning);
    }
  }

  private async Task PinChat(ChatDrawer.SidebarChat chat)
  {
    if (Guid.TryParse(chat.Id, out var chatId))
    {
      await ChatService.PinChatAsync(chatId, !chat.IsPinned);
      ChatCacheService.InvalidateCache(chatId);
      await LoadSidebarChatsAsync();
      if (_chatId == chat.Id) _chatIsPinned = !chat.IsPinned;
      StateHasChanged();
    }
  }

  private async Task DeleteChat(ChatDrawer.SidebarChat chat)
  {
    if (Guid.TryParse(chat.Id, out var chatId))
    {
      await ChatService.DeleteChatAsync(chatId);
      ChatCacheService.InvalidateCache(chatId);
      SidebarChats.RemoveAll(c => c.Id == chat.Id);
      if (_chatId == chat.Id)
      {
        await CreateNewChat();
      }

      StateHasChanged();
    }
  }

  private async Task HandleChatRenamed(ChatDrawer.SidebarChat updatedChat)
  {
    var fullChat = await ChatService.GetChatAsync(Guid.Parse(updatedChat.Id));
    var updateReq = new ChatService.UpdateChatRequest(
      updatedChat.Name,
      updatedChat.Model,
      fullChat.Messages, // These are ChatService.ChatMessageDto
      updatedChat.IsPinned
    );
    await ChatService.UpdateChatAsync(Guid.Parse(updatedChat.Id), updateReq);
    await LoadSidebarChatsAsync();
    if (_chatId == updatedChat.Id) _chatName = updatedChat.Name;
    StateHasChanged();
  }

  private async Task HandleRegenerateMessage(ChatMessage? messageToRegen)
  {
    if (_isSendingMessage) return;
    _isSendingMessage = true;
    StateHasChanged();
    await SignalRService.EnsureConnectionAsync();

    var idx = _chatHistory.IndexOf(messageToRegen);
    if (idx == -1)
    {
      _isSendingMessage = false;
      StateHasChanged();
      return;
    }

    List<ServiceChatMessage> messagesToSendForAi;
    ChatMessage? targetAiMessage;

    if (messageToRegen.IsUser)
    {
      _chatHistory.RemoveAll(m => _chatHistory.IndexOf(m) > idx && !m.IsUser);
      if (idx + 1 < _chatHistory.Count && !_chatHistory[idx + 1].IsUser)
      {
        _chatHistory.RemoveAt(idx + 1);
      }

      messagesToSendForAi = _chatHistory.Take(idx + 1)
        .Select(x => new ServiceChatMessage
        {
          Role = x.IsUser ? "user" : "assistant",
          Content = x.Text,
          FileIds = x.FileIds
        })
        .ToList();

      targetAiMessage = new ChatMessage { IsUser = false, Text = "", IsStreaming = true };
      if (idx + 1 < _chatHistory.Count) _chatHistory.Insert(idx + 1, targetAiMessage);
      else _chatHistory.Add(targetAiMessage);
    }
    else
    {
      _chatHistory[idx] = new ChatMessage { IsUser = false, Text = "", IsStreaming = true };
      targetAiMessage = _chatHistory[idx];

      messagesToSendForAi = _chatHistory.Take(idx)
        .Select(x => new ServiceChatMessage
        {
          Role = x.IsUser ? "user" : "assistant",
          Content = x.Text,
          FileIds = x.FileIds
        })
        .ToList();
    }

    _needsScroll = true;
    StateHasChanged();

    try
    {
      // Buffering implementation
      var buffer = new System.Text.StringBuilder();
      var lastUpdateTime = DateTime.MinValue;
      var updateInterval = TimeSpan.FromMilliseconds(300);

      // Start streaming via SignalR
      await ChatCompletionService.StreamCompletion(
        messagesToSendForAi,
        ChatSelectedModel,
        ThinkingSelectedOption,
        chunk =>
        {
          buffer.Append(chunk);

          var now = DateTime.UtcNow;
          if (now - lastUpdateTime >= updateInterval)
          {
            targetAiMessage.Text += buffer.ToString();
            buffer.Clear();
            lastUpdateTime = now;
            _needsScroll = true;
            StateHasChanged();
          }
        },
        async () => // This needs to be async Func<Task> as well
        {
          // Flush any remaining buffered content
          if (buffer.Length > 0)
          {
            targetAiMessage.Text += buffer.ToString();
            buffer.Clear();
          }

          targetAiMessage.IsStreaming = false;
          _isSendingMessage = false;
          StateHasChanged();
          await SaveChatAfterStreaming(); // Await this
        },
        error =>
        {
          if (buffer.Length > 0)
          {
            targetAiMessage.Text += buffer.ToString();
            buffer.Clear();
          }

          targetAiMessage.Text = $"[Error: {error}]";
          targetAiMessage.IsStreaming = false;
          _isSendingMessage = false;
          StateHasChanged();
        }
      );
    }
    catch (Exception ex)
    {
      targetAiMessage.Text = $"[Error regenerating: {ex.Message}]";
      Console.WriteLine($"Error regenerating message: {ex}");
      StateHasChanged();
      _isSendingMessage = false;
    }
  }


  private void HandleEditMessage(ChatMessage? m)
  {
    _messageBeingEdited = m; // Set the message being edited
    MessageText = m.Text;
    // Restore files for editing if they were part of this message
    CurrentMessageFiles = m.FileIds
      .Select(fid => new FileUploadService.UploadedFileInfo { Id = fid, OriginalFileName = $"File_{fid.ToString()[..4]}..." }) // Placeholder name, real info not stored here
      .ToList();

    // Show file upload if there are files to edit
    if (CurrentMessageFiles.Any())
    {
      _showFileUpload = true;
    }

    Snackbar.Add("Message content and associated files (if any) restored for editing.", Severity.Info);
    StateHasChanged();
  }


  private async Task HandleCopyMessage(ChatMessage? m)
  {
    try
    {
      await Js.InvokeVoidAsync("navigator.clipboard.writeText", m.Text);
      Snackbar.Add("Message copied to clipboard", Severity.Success);
    }
    catch (Exception ex)
    {
      Snackbar.Add($"Failed to copy: {ex.Message}", Severity.Error);
    }
  }

  private async Task HandleBranchMessage(ChatMessage? messageToBranchFrom)
  {
    var idx = _chatHistory.IndexOf(messageToBranchFrom);
    if (idx == -1) return;

    var branchChatHistory = _chatHistory.Take(idx + 1).ToList(); // List of local ChatMessage

    var branchName = $"Branch: {_chatName}".Truncate(50);
    var createReq = new ChatService.CreateChatRequest(
      branchName,
      ChatSelectedModel,
      branchChatHistory.Select(m => new ChatService.ChatMessageDto(
        m.IsUser ? "user" : "assistant",
        m.Text,
        m.FileIds)
      ).ToArray(),
      false
    );
    var newId = await ChatService.CreateChatAsync(createReq);

    await LoadSidebarChatsAsync();

    var newSidebarChat = SidebarChats.FirstOrDefault(c => c.Id == newId.ToString());
    if (newSidebarChat != null)
    {
      await LoadChat(newSidebarChat);
      Snackbar.Add("Chat branched successfully", Severity.Success);
    }
    else
    {
      _chatId = newId.ToString();
      _chatName = branchName;
      _chatHistory = branchChatHistory; // Assign the branched history
      _chatIsPinned = false;
      CurrentMessageFiles.Clear(); // Clear any pending files for the new branch
      _showFileUpload = false; // Hide file upload for new branch
      NavigationManager.NavigateTo($"/Chat?chatId={_chatId}", forceLoad: false);
      Snackbar.Add("Chat branched, but could not auto-load. Please select from sidebar.", Severity.Warning);
      StateHasChanged();
    }
  }

  public void Dispose()
  {
    // Unsubscribe from SignalR events - these are now handled per-stream in ChatCompletionService
    // SignalRService.OnChunkReceived -= HandleChunkReceived;
    // SignalRService.OnStreamCompleted -= HandleStreamCompleted;
    // SignalRService.OnStreamError -= HandleStreamError;
  }

  // This is the local record for UI state in Chat.razor
  private record ChatMessage
  {
    public string Id { get; init; } = Guid.NewGuid().ToString();
    public bool IsUser { get; init; }
    public string Text { get; set; } = ""; // Property is 'Text'
    public List<Guid> FileIds { get; init; } = new();
    public bool IsStreaming { get; set; }
  }

}
